# Initialisation

!pip install requests bs4

# Script

import requests
from bs4 import BeautifulSoup
import json

## Récupérer le contenu des pages

responses = []
for i in range(1, 10):
  req = requests.get(f"https://www.frameip.com/liste-des-ports-tcp-udp/?plage={i}")
  responses.append(req.content)

## Extraire les données des pages

# soups = []
# for resp in responses:
#   soups.append(BeautifulSoup(resp))
soups = [BeautifulSoup(resp) for resp in responses]

soups_rows = []
for soup in soups:
  soup_table = soup.find("table")
  soups_rows += soup_table.find_all("tr")[1:]

all_ports = {}

for soup_row in soups_rows:
  port_number = soup_row.find("a").string
  all_ports[port_number] = {}

print(all_ports)

for soup_row in soups_rows:
  port_number = soup_row.find("a").string
  port_protocol = soup_row.find_all("a")[1].string
  all_ports[port_number][port_protocol] = {}

print(all_ports)

for soup_row in soups_rows:
  port_number = soup_row.find("a").string
  port_protocol = soup_row.find_all("a")[1].string
  port_label = soup_row.find("p").string.strip()
  port_desc = soup_row.find_all("p")[3].string.strip()
  all_ports[port_number][port_protocol][port_label] = port_desc

print(all_ports)

## Sauvegarder les données dans un fichier JSON

with open("ports.json", "w") as ports_file:
  json.dump(all_ports, ports_file)
